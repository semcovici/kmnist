{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard, CSVLogger\n",
    "import pandas as pd\n",
    "import gc\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "sys.path.append('../src')\n",
    "from data.utils import load\n",
    "from models.create_models import create_cnn_model, create_fcnn_model\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/\"\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "\n",
    "PATH_MODELS = \"../models/\"\n",
    "PATH_LOGS = \"../logs/\"\n",
    "RESULTS_PATH = \"../results/\"\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "X_train = load(data_dir + 'kmnist-train-imgs.npz')\n",
    "X_test = load(data_dir + 'kmnist-test-imgs.npz')\n",
    "y_train = load(data_dir + 'kmnist-train-labels.npz')\n",
    "y_test = load(data_dir + 'kmnist-test-labels.npz')\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('{} train samples, {} test samples'.format(len(X_train), len(X_test)))\n",
    "print(f'Input shape: {input_shape}')\n",
    "\n",
    "# coleta dos valores unicos e das contagens\n",
    "unique_train, counts_train = np.unique(y_train, return_counts=True)\n",
    "unique_test, counts_test = np.unique(y_test, return_counts=True)\n",
    "\n",
    "num_classes = len(unique_train) if list(unique_train) == list(unique_test) else None\n",
    "\n",
    "\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criar conjunto aumentado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie o gerador de dados com data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=False,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Supomos que você tenha suas imagens de treino em x_train e labels em y_train\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Defina o número de amostras aumentadas que você deseja criar\n",
    "num_augmented_samples = len(X_train) * 10  # por exemplo, 10 vezes o conjunto original\n",
    "\n",
    "# Inicialize arrays para armazenar os dados aumentados\n",
    "X_train_augmented = np.zeros((num_augmented_samples, *X_train.shape[1:]), dtype=np.float32)\n",
    "y_train_augmented = np.zeros((num_augmented_samples, *y_train.shape[1:]), dtype=np.float32)\n",
    "\n",
    "# Gere os dados aumentados\n",
    "i = 0\n",
    "for x_batch, y_batch in datagen.flow(X_train, y_train, batch_size=BATCH_SIZE):\n",
    "    if i >= num_augmented_samples:\n",
    "        break\n",
    "    batch_size_aux = x_batch.shape[0]\n",
    "    X_train_augmented[i:i+batch_size_aux] = x_batch\n",
    "    y_train_augmented[i:i+batch_size_aux] = y_batch\n",
    "    i += batch_size_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num class train: \", len(unique_train))\n",
    "print(\"Num class test: \", len(unique_test))\n",
    "\n",
    "\n",
    "print('### Treino ###')\n",
    "for i in range(len(unique_train)): print(f'classe {unique_train[i]}: {counts_train[i]} observações')\n",
    "print('\\n### Teste ###')\n",
    "for i in range(len(unique_test)): print(f'classe {unique_test[i]}: {counts_test[i]} observações')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS =[\n",
    "        'accuracy',\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall'),\n",
    "        keras.metrics.AUC(name='auc'),\n",
    "        keras.metrics.TruePositives(name='tp'),\n",
    "        keras.metrics.TrueNegatives(name='tn'),\n",
    "        keras.metrics.FalsePositives(name='fp'),\n",
    "        keras.metrics.FalseNegatives(name='fn')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "source": [
    "### CNN Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks do modelo benchmark\n",
    "callbacks_benchmark = [\n",
    "    ModelCheckpoint(PATH_MODELS + f'best_model_CNN_benchmark.keras', save_best_only=True, monitor='val_loss'),\n",
    "    TensorBoard(log_dir=PATH_LOGS),\n",
    "    CSVLogger(PATH_MODELS + f'training_log_CNN_benchmark.csv')\n",
    "]\n",
    "\n",
    "# limpa sessao do keras\n",
    "keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "# cria modelo\n",
    "model_benchmark = create_cnn_model(\n",
    "    input_shape=input_shape,\n",
    "    num_classes= num_classes,\n",
    "    metrics= METRICS\n",
    ")\n",
    "\n",
    "# treina modelo\n",
    "history_benchmark = model_benchmark.fit(X_train, y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=12,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks = callbacks_benchmark\n",
    "          )\n",
    "\n",
    "# realiza predicao\n",
    "train_pred_proba = model_benchmark.predict(X_train)\n",
    "test_pred_proba = model_benchmark.predict(X_test)\n",
    "\n",
    "# salva predicao no treino\n",
    "test_results_benchmark = pd.DataFrame({\n",
    "    \"y_test\": y_test.argmax(axis=1),\n",
    "    \"y_test_pred\": np.argmax(test_pred_proba, axis =1),\n",
    "    \"y_test_pred_proba\": list(test_pred_proba)\n",
    "    \n",
    "})\n",
    "test_results_benchmark.to_csv(RESULTS_PATH + 'test/cnn_benchmark_test_results.csv', index = False)\n",
    "\n",
    "# salva predicao no teste\n",
    "train_results_benchmark = pd.DataFrame({\n",
    "    \"y_train\": y_train.argmax(axis=1),\n",
    "    \"y_train_pred\": np.argmax(train_pred_proba, axis =1),\n",
    "    \"y_train_pred_proba\": list(train_pred_proba)\n",
    "})\n",
    "train_results_benchmark.to_csv(RESULTS_PATH + 'train/cnn_benchmark_train_results.csv', index = False)\n",
    "\n",
    "json.dump(history_benchmark.history, open(RESULTS_PATH + \"history/benchmark_cnn_history.json\", \"w\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extraindo os pesos da primeira camada convolucional\n",
    "filters, biases = model_benchmark.layers[0].get_weights()\n",
    "n_filters = filters.shape[-1]\n",
    "\n",
    "# Normalizando os filtros para a faixa [0, 1]\n",
    "filters_min = filters.min()\n",
    "filters_max = filters.max()\n",
    "filters = (filters - filters_min) / (filters_max - filters_min)\n",
    "\n",
    "# Visualizando os filtros\n",
    "fig, axs = plt.subplots(1, n_filters, figsize=(20, 20))\n",
    "for i in range(n_filters):\n",
    "    f = filters[:, :, :, i]\n",
    "    axs[i].imshow(f[:, :, 0], cmap='gray')\n",
    "    axs[i].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Com Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks do modelo benchmark\n",
    "callbacks_benchmark_aug = [\n",
    "    ModelCheckpoint(PATH_MODELS + f'best_model_CNN_aug_benchmark.keras', save_best_only=True, monitor='val_loss'),\n",
    "    TensorBoard(log_dir=PATH_LOGS),\n",
    "    CSVLogger(PATH_MODELS + f'training_log_CNN_aug_benchmark.csv')\n",
    "]\n",
    "\n",
    "# limpa sessao do keras\n",
    "keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "# cria modelo\n",
    "model_benchmark_aug = create_cnn_model(\n",
    "    input_shape=input_shape,\n",
    "    num_classes= num_classes,\n",
    "    metrics= METRICS\n",
    ")\n",
    "\n",
    "# treina modelo\n",
    "history_benchmark_aug = model_benchmark_aug.fit(X_train_augmented, y_train_augmented,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=12,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks = callbacks_benchmark_aug\n",
    "          )\n",
    "\n",
    "# realiza predicao\n",
    "train_pred_proba = model_benchmark_aug.predict(X_train)\n",
    "test_pred_proba = model_benchmark_aug.predict(X_test)\n",
    "\n",
    "# salva predicao no treino\n",
    "test_results_benchmark_aug = pd.DataFrame({\n",
    "    \"y_test\": y_test.argmax(axis=1),\n",
    "    \"y_test_pred\": np.argmax(test_pred_proba, axis =1),\n",
    "    \"y_test_pred_proba\": list(test_pred_proba)\n",
    "    \n",
    "})\n",
    "test_results_benchmark_aug.to_csv(RESULTS_PATH + 'test/cnn_benchmark_aug_test_results.csv', index = False)\n",
    "\n",
    "# salva predicao no teste\n",
    "train_results_benchmark_aug = pd.DataFrame({\n",
    "    \"y_train\": y_train.argmax(axis=1),\n",
    "    \"y_train_pred\": np.argmax(train_pred_proba, axis =1),\n",
    "    \"y_train_pred_proba\": list(train_pred_proba)\n",
    "})\n",
    "train_results_benchmark_aug.to_csv(RESULTS_PATH + 'train/cnn_benchmark_aug_train_results.csv', index = False)\n",
    "\n",
    "json.dump(history_benchmark_aug.history, open(RESULTS_PATH + \"history/benchmark_aug_cnn_history.json\", \"w\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks cnn\n",
    "callbacks_cnn = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10),\n",
    "    ModelCheckpoint(PATH_MODELS + f'best_model_CNN.keras', save_best_only=True, monitor='val_loss'),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5),\n",
    "    TensorBoard(log_dir=PATH_LOGS),\n",
    "    CSVLogger(PATH_MODELS + f'training_log_CNN.csv')\n",
    "]\n",
    "\n",
    "# limpa sessao do keras\n",
    "keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "# cria modelo\n",
    "model_cnn = create_cnn_model(\n",
    "    input_shape=input_shape,\n",
    "    num_classes= num_classes,\n",
    "    metrics = METRICS\n",
    ")\n",
    "\n",
    "# treina modelo\n",
    "history_cnn = model_cnn.fit(X_train, y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=callbacks_cnn\n",
    "          )\n",
    "\n",
    "\n",
    "# realiza predicao\n",
    "train_pred_proba = model_cnn.predict(X_train)\n",
    "test_pred_proba = model_cnn.predict(X_test)\n",
    "\n",
    "# salva predicao no treino\n",
    "test_results_cnn = pd.DataFrame({\n",
    "    \"y_test\": y_test.argmax(axis=1),\n",
    "    \"y_test_pred\": np.argmax(test_pred_proba, axis =1),\n",
    "    \"y_test_pred_proba\": list(test_pred_proba)\n",
    "    \n",
    "})\n",
    "test_results_cnn.to_csv(RESULTS_PATH + 'test/cnn_test_results.csv', index = False)\n",
    "\n",
    "# salva predicao no teste\n",
    "train_results_cnn = pd.DataFrame({\n",
    "    \"y_train\": y_train.argmax(axis=1),\n",
    "    \"y_train_pred\": np.argmax(train_pred_proba, axis =1),\n",
    "    \"y_train_pred_proba\": list(train_pred_proba)\n",
    "})\n",
    "train_results_cnn.to_csv(RESULTS_PATH + 'train/cnn_train_results.csv', index = False)\n",
    "\n",
    "\n",
    "json.dump(history_cnn.history, open(RESULTS_PATH + \"history/cnn_history.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sem pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks cnn\n",
    "callbacks_cnn_wo_poll = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10),\n",
    "    ModelCheckpoint(PATH_MODELS + f'best_model_CNN_without_polling.keras', save_best_only=True, monitor='val_loss'),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5),\n",
    "    TensorBoard(log_dir=PATH_LOGS),\n",
    "    CSVLogger(PATH_MODELS + f'training_log_CNN_without_polling.csv')\n",
    "]\n",
    "\n",
    "# limpa sessao do keras\n",
    "keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "# cria modelo\n",
    "model_cnn_wo_poll = create_cnn_model(\n",
    "    input_shape=input_shape,\n",
    "    num_classes= num_classes,\n",
    "    metrics = METRICS,\n",
    "    polling = False\n",
    ")\n",
    "\n",
    "# treina modelo\n",
    "history_cnn_wo_poll = model_cnn_wo_poll.fit(X_train, y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=callbacks_cnn_wo_poll\n",
    "          )\n",
    "\n",
    "\n",
    "# realiza predicao\n",
    "train_pred_proba = model_cnn_wo_poll.predict(X_train)\n",
    "test_pred_proba = model_cnn_wo_poll.predict(X_test)\n",
    "\n",
    "# salva predicao no treino\n",
    "test_results_cnn_wo_poll = pd.DataFrame({\n",
    "    \"y_test\": y_test.argmax(axis=1),\n",
    "    \"y_test_pred\": np.argmax(test_pred_proba, axis =1),\n",
    "    \"y_test_pred_proba\": list(test_pred_proba)\n",
    "    \n",
    "})\n",
    "test_results_cnn_wo_poll.to_csv(RESULTS_PATH + 'test/cnn_without_polling_test_results.csv', index = False)\n",
    "\n",
    "# salva predicao no teste\n",
    "train_results_cnn_wo_poll = pd.DataFrame({\n",
    "    \"y_train\": y_train.argmax(axis=1),\n",
    "    \"y_train_pred\": np.argmax(train_pred_proba, axis =1),\n",
    "    \"y_train_pred_proba\": list(train_pred_proba)\n",
    "})\n",
    "train_results_cnn_wo_poll.to_csv(RESULTS_PATH + 'train/cnn_without_polling_train_results.csv', index = False)\n",
    "\n",
    "\n",
    "json.dump(history_cnn_wo_poll.history, open(RESULTS_PATH + \"history/cnn_without_polling_history.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Com data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks cnn\n",
    "callbacks_cnn_aug = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10),\n",
    "    ModelCheckpoint(PATH_MODELS + f'best_model_CNN_aug.keras', save_best_only=True, monitor='val_loss'),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5),\n",
    "    TensorBoard(log_dir=PATH_LOGS),\n",
    "    CSVLogger(PATH_MODELS + f'training_log_CNN_aug.csv')\n",
    "]\n",
    "\n",
    "# limpa sessao do keras\n",
    "keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "# cria modelo\n",
    "model_cnn_aug = create_cnn_model(\n",
    "    input_shape=input_shape,\n",
    "    num_classes= num_classes,\n",
    "    metrics = METRICS\n",
    ")\n",
    "\n",
    "# treina modelo\n",
    "history_cnn_aug = model_cnn_aug.fit(X_train_augmented, y_train_augmented,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=callbacks_cnn_aug\n",
    "          )\n",
    "\n",
    "\n",
    "# realiza predicao\n",
    "train_pred_proba = model_cnn_aug.predict(X_train)\n",
    "test_pred_proba = model_cnn_aug.predict(X_test)\n",
    "\n",
    "# salva predicao no treino\n",
    "test_results_cnn_aug = pd.DataFrame({\n",
    "    \"y_test\": y_test.argmax(axis=1),\n",
    "    \"y_test_pred\": np.argmax(test_pred_proba, axis =1),\n",
    "    \"y_test_pred_proba\": list(test_pred_proba)\n",
    "    \n",
    "})\n",
    "test_results_cnn_aug.to_csv(RESULTS_PATH + 'test/cnn_aug_test_results.csv', index = False)\n",
    "\n",
    "# salva predicao no teste\n",
    "train_results_cnn_aug = pd.DataFrame({\n",
    "    \"y_train\": y_train.argmax(axis=1),\n",
    "    \"y_train_pred\": np.argmax(train_pred_proba, axis =1),\n",
    "    \"y_train_pred_proba\": list(train_pred_proba)\n",
    "})\n",
    "train_results_cnn_aug.to_csv(RESULTS_PATH + 'train/cnn_aug_train_results.csv', index = False)\n",
    "\n",
    "\n",
    "json.dump(history_cnn_aug.history, open(RESULTS_PATH + \"history/cnn_aug_history.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks cnn\n",
    "callbacks_fcnn = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10),\n",
    "    ModelCheckpoint(PATH_MODELS + f'best_model_fcnn.keras', save_best_only=True, monitor='val_loss'),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5),\n",
    "    TensorBoard(log_dir=PATH_LOGS),\n",
    "    CSVLogger(PATH_MODELS + f'training_log_fcnn.csv')\n",
    "]\n",
    "\n",
    "# limpa sessao do keras\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# cria modelo\n",
    "model_fcnn = create_fcnn_model(\n",
    "    input_shape=input_shape,\n",
    "    num_classes= num_classes,\n",
    "    metrics = METRICS\n",
    ")\n",
    "\n",
    "# treina modelo\n",
    "history_fcnn = model_fcnn.fit(X_train, y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=callbacks_fcnn\n",
    "          )\n",
    "\n",
    "\n",
    "# realiza predicao\n",
    "train_pred_proba = model_fcnn.predict(X_train)\n",
    "test_pred_proba = model_fcnn.predict(X_test)\n",
    "\n",
    "# salva predicao no treino\n",
    "test_results_fcnn = pd.DataFrame({\n",
    "    \"y_test\": y_test.argmax(axis=1),\n",
    "    \"y_test_pred\": np.argmax(test_pred_proba, axis =1),\n",
    "    \"y_test_pred_proba\": list(test_pred_proba)\n",
    "    \n",
    "})\n",
    "test_results_fcnn.to_csv(RESULTS_PATH + 'test/fcnn_test_results.csv', index = False)\n",
    "\n",
    "\n",
    "# salva predicao no teste\n",
    "train_results_fcnn = pd.DataFrame({\n",
    "    \"y_train\": y_train.argmax(axis=1),\n",
    "    \"y_train_pred\": np.argmax(train_pred_proba, axis =1),\n",
    "    \"y_train_pred_proba\": list(train_pred_proba)\n",
    "})\n",
    "train_results_fcnn.to_csv(RESULTS_PATH + 'train/fcnn_train_results.csv', index = False)\n",
    "\n",
    "\n",
    "json.dump(history_fcnn.history, open(RESULTS_PATH + \"history/fcnn_history.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### com data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# callbacks cnn\n",
    "callbacks_fcnn_aug = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10),\n",
    "    ModelCheckpoint(PATH_MODELS + f'best_model_fcnn_aug.keras', save_best_only=True, monitor='val_loss'),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5),\n",
    "    TensorBoard(log_dir=PATH_LOGS),\n",
    "    CSVLogger(PATH_MODELS + f'training_log_fcnn_aug.csv')\n",
    "]\n",
    "\n",
    "# limpa sessao do keras\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# cria modelo\n",
    "model_fcnn_aug = create_fcnn_model(\n",
    "    input_shape=input_shape,\n",
    "    num_classes= num_classes,\n",
    "    metrics = METRICS\n",
    ")\n",
    "\n",
    "# treina modelo\n",
    "history_fcnn_aug = model_fcnn_aug.fit(X_train_augmented, y_train_augmented,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=callbacks_fcnn_aug\n",
    "          )\n",
    "\n",
    "\n",
    "# realiza predicao\n",
    "train_pred_proba = model_fcnn_aug.predict(X_train)\n",
    "test_pred_proba = model_fcnn_aug.predict(X_test)\n",
    "\n",
    "# salva predicao no treino\n",
    "test_results_fcnn_aug = pd.DataFrame({\n",
    "    \"y_test\": y_test.argmax(axis=1),\n",
    "    \"y_test_pred\": np.argmax(test_pred_proba, axis =1),\n",
    "    \"y_test_pred_proba\": list(test_pred_proba)\n",
    "    \n",
    "})\n",
    "test_results_fcnn_aug.to_csv(RESULTS_PATH + 'test/fcnn_aug_test_results.csv', index = False)\n",
    "\n",
    "\n",
    "# salva predicao no teste\n",
    "train_results_fcnn_aug = pd.DataFrame({\n",
    "    \"y_train\": y_train.argmax(axis=1),\n",
    "    \"y_train_pred\": np.argmax(train_pred_proba, axis =1),\n",
    "    \"y_train_pred_proba\": list(train_pred_proba)\n",
    "})\n",
    "train_results_fcnn_aug.to_csv(RESULTS_PATH + 'train/fcnn_aug_train_results.csv', index = False)\n",
    "\n",
    "\n",
    "json.dump(history_fcnn_aug.history, open(RESULTS_PATH + \"history/fcnn_aug_history.json\", \"w\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-kmnist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
